# Ollama Configuration
OLLAMA_MODEL=mistral              # Options: mistral, llama2, mixtral, phi
EMBEDDING_MODEL=nomic-embed-text  # Best for embeddings
OLLAMA_HOST=ollama               # Use 'localhost' for local development
OLLAMA_PORT=11434
OLLAMA_KEEP_ALIVE=24h            # Keep models loaded in memory

# Application Settings
APP_ENV=development
LOG_LEVEL=INFO
MAX_UPLOAD_SIZE_MB=50

# Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
CHUNK_MIN_SIZE=100

# Vector Store Settings
VECTOR_STORE_TYPE=chroma
CHROMA_PERSIST_DIR=./chroma_db
SIMILARITY_TOP_K=5

# DECIMER Settings
DECIMER_API_URL=https://www.decimer.ai/process_image
DECIMER_TIMEOUT=30
DECIMER_MAX_RETRIES=3

# Streamlit Configuration
STREAMLIT_THEME=light
STREAMLIT_MAX_MESSAGE_SIZE=200