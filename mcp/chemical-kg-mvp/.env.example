# Ollama Configuration
OLLAMA_MODEL=mistral              # Options: mistral, llama2, mixtral, phi
EMBEDDING_MODEL=nomic-embed-text  # Best for embeddings
OLLAMA_HOST=ollama               # Use 'localhost' for local development
OLLAMA_PORT=11434
OLLAMA_KEEP_ALIVE=24h            # Keep models loaded in memory

# Application Settings
APP_ENV=development
LOG_LEVEL=INFO
MAX_UPLOAD_SIZE_MB=50

# Chunking Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
CHUNK_MIN_SIZE=100

# Vector Store Settings
VECTOR_STORE_TYPE=chroma
CHROMA_PERSIST_DIR=./chroma_db
SIMILARITY_TOP_K=5

# DECIMER Settings
DECIMER_API_URL=https://www.decimer.ai/process_image
DECIMER_TIMEOUT=30
DECIMER_MAX_RETRIES=3

# Streamlit Configuration
STREAMLIT_THEME=light
STREAMLIT_MAX_MESSAGE_SIZE=200
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0

# Development Settings
PYTHONUNBUFFERED=1
PYTHONDONTWRITEBYTECODE=1

# Chemical Processing Settings
MAX_IMAGE_SIZE_MB=10
SUPPORTED_IMAGE_FORMATS=png,jpg,jpeg,gif,bmp
CHEMICAL_CONTEXT_WINDOW=5

# Performance Settings
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=30
CACHE_TTL=3600

# Security Settings (for production)
# ALLOWED_ORIGINS=http://localhost:8501
# ENABLE_HTTPS=false
# SSL_CERT_PATH=
# SSL_KEY_PATH=